---
title: Contains
author: Fabiano Honorato
patat:
    wrap: true
#    slideLevel: 1
...

# Introduction

## Introduction. Bio (who am i).

## Introduction. A little of history about containers.

## Introduction. Which tools we are going to use.

> * Linux (our container will be a bootstraped from Arch Linux)
> * namespaces
> * cgroups
> * unshare
> * iptables
> * Docker (in the final we will import our container to Docker so we can reuse it)

## Introduction. Advantages of using containers.

> * No operational system dependency (a container will - most of the times - behave the same under any OS)
> * Resource optimization
> * Scaling speed
> * Infrastructure control

## Introduction. What containers are not.

> * They are not emulation;
> * Containers are not VMs;
> * They are not an engine (altough we might use one to manage them).

## Introduction. What a container is?

A container is about isolating a process within certains host resources.

. . .

And this is done by the linux kernel, in each of its subsystems. Using namespaces and cgroups, here are the namespaces:

    Mount (mnt)
        - Filesystem mounting management
    
    Process ID (pid)
        - PID isolation
    
    Network (net)
        - Networking isolation
    
    Interprocess Communication (ipc)
        - Process communication, share of data and events.
    
    UTS
        - System identification
    
    User ID (user)
        - Permission administration
    
    Control group (cgroup)
        - Resource usage control

. . .

A host system can have many of each namespaces, and each process can only see and use resources of that specific namespace.

. . .

Let's say we have the process 'ls' and 'cat', each on a different 'mnt' namespace:

* ls -> mnt:[1111111111]
* cat -> mnt:[2222222222]

. . .

Even if we run this with the same arguments, let's say 'file', we are going access different files.

# Namespaces

## Namespaces.

Each process its bound to a namespace of each type (mnt, pid, net, etc).

. . .

    sudo ls -ltrh /proc/1/ns/

. . .

    total 0
    lrwxrwxrwx 1 root root 0 fev  3 00:15 uts -> 'uts:[4026531838]'
    lrwxrwxrwx 1 root root 0 fev  3 00:15 user -> 'user:[4026531837]'
    lrwxrwxrwx 1 root root 0 fev  3 00:15 pid_for_children -> 'pid:[4026531836]'
    lrwxrwxrwx 1 root root 0 fev  3 00:15 pid -> 'pid:[4026531836]'
    lrwxrwxrwx 1 root root 0 fev  3 00:15 net -> 'net:[4026532008]'
    lrwxrwxrwx 1 root root 0 fev  3 00:15 mnt -> 'mnt:[4026531840]'
    lrwxrwxrwx 1 root root 0 fev  3 00:15 ipc -> 'ipc:[4026531839]'
    lrwxrwxrwx 1 root root 0 fev  3 00:15 cgroup -> 'cgroup:[4026531835]'

## Namespaces.

Let's take a look at the processes namespaces.

. . . 

    sudo ps ax -o pid,ppid,pidns,cmd --forest

. . . 

    PID    PPID      PIDNS CMD
    [...]
      1       0 4026531836 /sbin/init splash
    325       1 4026531836 /usr/lib/systemd/systemd-journald1
    332       1 4026531836 /usr/bin/lvmetad -f1
    341       1 4026531836 /usr/lib/systemd/systemd-udevd1
    421       1 4026531836 /usr/lib/systemd/systemd-timesyncd1
    478       1 4026531836 /usr/bin/bumblebeed1
    479       1 4026531836 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation -
    480       1 4026531836 /usr/bin/NetworkManager --no-daemon1
    505       1 4026531836 /usr/lib/systemd/systemd-logind1
    524       1 4026531836 /usr/bin/wpa_supplicant -u -s -O /run/wpa_supplicant1
    529       1 4026531836 /usr/bin/sddm1
    531     529 4026531836  \_ /usr/lib/Xorg -nolisten tcp -auth /var/run/sddm/{c3b90c51-25fb-41ad-8a41-c4fbb9073d24} -
    610     529 4026531836  \_ /usr/lib/sddm/sddm-helper --socket /tmp/sddm-auth950ddf17-00b2-4a57-a9b7-4f9f1e35321e --
    622     610 4026531836      \_ /usr/bin/startplasma-x111
    666     622 4026531836          \_ /usr/bin/plasma_session1
    562       1 4026531836 /usr/lib/udisks2/udisksd1
    566       1 4026531836 /usr/lib/polkit-1/polkitd --no-debug1
    582       1 4026531836 /usr/lib/upowerd1
    614       1 4026531836 /usr/lib/systemd/systemd --user1
    [...]

. . .
    
Mind the column PIDNS which describes the namespace ID within in the PID namespace.

# Enough talk, let's make a container from scratch!

## Container from scratch. OS files.

First thing we need is the files for the operational system.

. . .

    sudo mkdir system-root && sudo pacstrap system-root base base-devel

. . .

    ==> Creating install root at system-root
    ==> Installing packages to system-root
    :: Synchronizing package databases...
    core                         133,5 KiB   193 KiB/s 00:01 [###################################################] 100%
    extra                       1640,3 KiB   387 KiB/s 00:04 [###################################################] 100%
    community                      4,8 MiB   383 KiB/s 00:13 [###################################################] 100%
    archlinuxfr                    9,4 KiB   284 KiB/s 00:00 [###################################################] 100%
    multilib                     161,8 KiB   462 KiB/s 00:00 [###################################################] 100%
    
    [...]

    error: command failed to execute correctly
    ( 7/12) Reloading device manager configuration...
    Running in chroot, ignoring request.
    ( 8/12) Arming ConditionNeedsUpdate...
    ( 9/12) Reloading system bus configuration...
    Running in chroot, ignoring request: try-reload-or-restart
    (10/12) Warn about old perl modules
    perl: warning: Setting locale failed.
    perl: warning: Please check that your locale settings:
            LANGUAGE = "en_US",
            LC_ALL = (unset),
            LANG = "pt_BR.UTF-8"
        are supported and installed on your system.
    perl: warning: Falling back to the standard locale ("C").
    (11/12) Updating the info directory file...
    (12/12) Rebuilding certificate stores...

Here I'm using Arch Linux pacstrap, but you could use debootstrap for debian, yum to install the base package for Centos or even apk to install alpine base package.

## Container from scratch. Exploring the jail.

Now that we have our system files, we can change our root filesystem to it (we call that a jail).

. . . 

The running process can't access any file above the filesystem tree (in our case the host files).

. . . 

    sudo chroot system-root

. . . 

    [root@StrikerEureka /]# ls
    bin  boot  dev  etc  home  lib  lib64  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
    [root@StrikerEureka /]# 

. . . 

Now let's check the running processes:

. . . 

    ps ax -o pid,ppid,pidns,cmd --forest

. . .

    Error, do this: mount -t proc proc /proc

Ops!

## Container from scratch. Procceses inside the jail.

We can't see the running procceses, because they depend on /proc structure.

. . .

    mount -t proc none /proc

. . .

Now let's check the running processes again:

    ps ax -o pid,ppid,pidns,cmd --forest

. . .

    PID    PPID      PIDNS CMD
    [...]
      1       0 4026531836 /sbin/init splash
    325       1 4026531836 /usr/lib/systemd/systemd-journald1
    332       1 4026531836 /usr/bin/lvmetad -f1
    341       1 4026531836 /usr/lib/systemd/systemd-udevd1
    421       1 4026531836 /usr/lib/systemd/systemd-timesyncd1
    478       1 4026531836 /usr/bin/bumblebeed1
    479       1 4026531836 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation -
    480       1 4026531836 /usr/bin/NetworkManager --no-daemon1
    505       1 4026531836 /usr/lib/systemd/systemd-logind1
    524       1 4026531836 /usr/bin/wpa_supplicant -u -s -O /run/wpa_supplicant1
    529       1 4026531836 /usr/bin/sddm1
    531     529 4026531836  \_ /usr/lib/Xorg -nolisten tcp -auth /var/run/sddm/{c3b90c51-25fb-41ad-8a41-c4fbb9073d24} -
    610     529 4026531836  \_ /usr/lib/sddm/sddm-helper --socket /tmp/sddm-auth950ddf17-00b2-4a57-a9b7-4f9f1e35321e --
    622     610 4026531836      \_ /usr/bin/startplasma-x111
    666     622 4026531836          \_ /usr/bin/plasma_session1
    562       1 4026531836 /usr/lib/udisks2/udisksd1
    566       1 4026531836 /usr/lib/polkit-1/polkitd --no-debug1
    582       1 4026531836 /usr/lib/upowerd1
    614       1 4026531836 /usr/lib/systemd/systemd --user1
    [...]

## Container from scratch. Namespaces

But why do we see the host procceses?

. . .

Because we still using the host namespaces. So let's add new namespaces to the mix.

. . .

First, let's clear the change that we made to the jail and leave it.

    sudo umount /proc && exit

. . .

Then we're going to use unshare, an application made for dealing with namespaces.

    sudo unshare --mount --uts --ipc --net --pid --cgroup --fork chroot system-root bin/bash

. . .

Now, let's mount our empty /proc structure

    mount -t proc none /proc

. . .

Finally, let's check the procceses one more time:

. . .

    ps ax -o pid,ppid,pidns,cmd --forest

. . .

    [root@StrikerEureka /]# ps ax -o pid,ppid,pidns,cmd --forest
    PID    PPID      PIDNS CMD
    1       0 4026532738 /bin/bash -i
    6       1 4026532738 ps ax -o pid,ppid,pidns,cmd --forest

## Container from scratch. Cgroups (when things start to get exciting)

Now we are going to dive a little deeper on cgroups.

. . .

First for CPU, let's create this directory on the host:

    sudo mkdir /sys/fs/cgroup/cpu/contains

    sudo ls /sys/fs/cgroup/cpu/contains

. . .

We can check the current CPU resource limitation:

    sudo cat /sys/fs/cgroup/cpu/contains/cpu.cfs_period_us
    sudo cat /sys/fs/cgroup/cpu/contains/cpu.cfs_quota_us

. . .

Now let's limit our cgroup CFS quota.

    echo 50000 | sudo tee /sys/fs/cgroup/cpu/contains/cpu.cfs_quota_us

. . .

Then for memory:

    sudo mkdir /sys/fs/cgroup/memory/contains

    sudo ls /sys/fs/cgroup/memory/contains

. . .

And then limit the memory amount for our newly created cgroup. Let's also remove swappiness.

    echo 10000000 | sudo tee /sys/fs/cgroup/memory/contains/memory.limit_in_bytes
    echo 0 | sudo tee /sys/fs/cgroup/memory/contains/memory.swappiness

. . .

Finally, let's add our container to our cgroup:
    
    echo $(pgrep 'bash') | sudo tee /sys/fs/cgroup/cpu/contains/cgroup.procs
    echo $(pgrep 'bash') | sudo tee /sys/fs/cgroup/memory/contains/cgroup.procs

## Container from scratch. Network namespace

Now let's make sure our container has connectivity.

. . .

For that we need to create a virtual interface from the host.

    sudo ip link add name host type veth peer name container

. . .


Now, let's move the 'container' side of the virtual interface to the container net namespace.

    sudo ip link set container netns $(pgrep 'bash')

. . .


Virtual interfaces come disabled, let's turn on and add an IP on the host side.

    sudo ip link set host up
    sudo ip add add 10.1.0.1/24 dev host

. . .

Then turn then on at the container side. We also add the default route pointing to the host virtual interface since it's our only way out.

    ip link set container up
    ip add add 10.1.0.2/24 dev container
    ip route add default via 10.1.0.1

. . . 

We also need to make sure we have a DNS server to send our queries to.

    echo 'nameserver 8.8.8.8' > /etc/resolv.conf

. . .

Finally, on the host let's ensure we can forward network packets and that we have the necessary routes for the containers.

    sudo sysctl net.ipv4.conf.all.forwarding=1 # By default linux hosts don't forward IPv4 and IPv6 packets.

    sudo iptables -t nat -A POSTROUTING -s 10.1.0.0/24 -o wlp3s0 -j MASQUERADE
    sudo iptables -A FORWARD -o wlp3s0 -i host -j ACCEPT # Accept what comes from host interface to the virtual interface
    sudo iptables -A FORWARD -i wlp3s0 -o host -j ACCEPT # Accept what comes from virtual interface to the host interface

# Wraping up

## Wraping up. Installing nginx

Now, to see our container in action, let's install a nginx and access it from the host through our virtual interface.

. . .

You may noticed that so far we didn't mount any filesystem besides the /proc (linux has a lot of mounts like /dev /sys and /run besides the user ones). So let's do it so we can install our program.

    mount --bind / /

    rm -rf /etc/mtab && ln -s /proc/mounts /etc/mtab

    df -h

. . . 

    [root@StrikerEureka /]# df -h
    Filesystem      Size  Used Avail Use% Mounted on
    /dev/sdc2       110G   99G  5.2G  96% /

. . .

And now let's install nginx (for now we're going to disable pacman signature validation for the sake of simplicity).

    sed -i 's/SigLevel    = Required DatabaseOptional/SigLevel    = Never/' /etc/pacman.conf
    pacman -S --noconfirm nginx

Finally let's start nginx in background

    nginx
    ps ax -o pid,ppid,pidns,cmd --forest | grep nginx

# Overview

## Overview. What we done so far

Let's recap a few things.

> * Containers are not VMs, emulation or engine.
> * They consist mainly of system features called namespaces and cgroups.
> * Namespaces are way of isolate a specific process within certain host resources.
> * We can change our root directory to create a jail and use namespaces and cgroups to limit the jail context.
> * The setup described above is essencially what we can call a container.
> * We can create a virtual interface to connect the container and the host (or other containers).
> * We can install anything in our containers as if it were a normal operational system and we can do that in a isolated environment exposing only what we want.

. . .

That's a lot of stuff and concepts to grasp, no wonder we have container engines like docker, containerd or kubernetes.

# Docker

## Docker. Images

Speaking of Docker, since Docker images are tarballs we can transform our newly made container into a Docker image and run it as a Docker container.

. . .

Compress the container and import it as an Docker image from the host.

    cd system-root && sudo tar -czf ../system-root.tar.gz . # This will take a while

    cat ../system-root.tar.gz | docker import - contains:latest # This will also take a while

Create a Docker container from the image.

    docker run -d --rm -it --name contains -p 80:80 contains nginx -g 'daemon off;'

    docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' contains